{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rAYrfoEK6GPd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Re-Align HEB SRT\n",
        "\n",
        "When transcribing Hebrew audio using the Whisper transcription system (not WhisperX), the resulting subtitle blocks can sometimes be too short. This code aims to address this issue by merging subtitle blocks and returning an updated SRT file.\n",
        "\n",
        "The goal is to improve the readability and coherence of the subtitles by combining shorter blocks into longer ones, providing a more natural flow for the viewer.\n",
        "\n",
        "Yedidya Harris\n"
      ],
      "metadata": {
        "id": "OibcitsV5p6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "rAYrfoEK6GPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "def parse_srt_to_df(srt_file):\n",
        "    # Initialize an empty list to store block dictionaries\n",
        "    blocks = []\n",
        "\n",
        "    with open(srt_file, \"r\") as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    block_id = None\n",
        "    timestamp_start = None\n",
        "    timestamp_end = None\n",
        "    text = \"\"\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:  # Skip empty lines\n",
        "            continue\n",
        "        if block_id is None:\n",
        "            block_id = int(line)\n",
        "        elif timestamp_start is None:\n",
        "            timestamp_start, timestamp_end = line.split(\" --> \")\n",
        "        else:\n",
        "            if line.isdigit():  # Check if the line is a block ID for the next block\n",
        "                # Add the completed block to the list\n",
        "                blocks.append({\n",
        "                    \"block_id\": block_id,\n",
        "                    \"timestamp_start\": timestamp_start,\n",
        "                    \"timestamp_end\": timestamp_end,\n",
        "                    \"text\": text.strip()\n",
        "                })\n",
        "\n",
        "                # Reset variables for the next block\n",
        "                block_id = int(line)\n",
        "                timestamp_start = None\n",
        "                timestamp_end = None\n",
        "                text = \"\"\n",
        "            else:\n",
        "                text += line + \" \"\n",
        "\n",
        "    # Add the last block to the list\n",
        "    blocks.append({\n",
        "        \"block_id\": block_id,\n",
        "        \"timestamp_start\": timestamp_start,\n",
        "        \"timestamp_end\": timestamp_end,\n",
        "        \"text\": text.strip()\n",
        "    })\n",
        "\n",
        "    # Create a DataFrame from the list of block dictionaries\n",
        "    df = pd.DataFrame(blocks)\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "_jLVvr2QvTRf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def merge_text_pairs(df):\n",
        "    # Create an empty DataFrame for the new merged data\n",
        "    merged_df = pd.DataFrame(columns=['block_id', 'timestamp_start', 'timestamp_end', 'text'])\n",
        "\n",
        "    # Iterate through the original DataFrame rows in pairs\n",
        "    for i in range(0, len(df) - 1, 2):\n",
        "        row1 = df.iloc[i]\n",
        "        row2 = df.iloc[i + 1]\n",
        "\n",
        "        # Merge the text values with a comma in between\n",
        "        merged_text = row1['text'] + ', ' + row2['text']\n",
        "\n",
        "        # Extract the start and end timestamps from the rows\n",
        "        timestamp_start = row1['timestamp_start']\n",
        "        timestamp_end = row2['timestamp_end']\n",
        "\n",
        "        # Create a new row for the merged data\n",
        "        new_row = {\n",
        "            'block_id': row1['block_id'],\n",
        "            'timestamp_start': timestamp_start,\n",
        "            'timestamp_end': timestamp_end,\n",
        "            'text': merged_text\n",
        "        }\n",
        "\n",
        "        # Append the new row to the merged DataFrame\n",
        "        merged_df = pd.concat([merged_df, pd.DataFrame(new_row, index=[0])], ignore_index=True)\n",
        "        merged_df['block_id'] = range(1, len(merged_df) + 1)\n",
        "\n",
        "    return merged_df\n"
      ],
      "metadata": {
        "id": "6rk9njaAyQHE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def round_down_timestamps(df):\n",
        "    # Clear the timestamp_end column\n",
        "    df['timestamp_end'] = ''\n",
        "\n",
        "    # Fill in timestamp_end with rounded-down timestamp_start from the next row\n",
        "    for i in range(len(df) - 1):\n",
        "        start_time = df.loc[i, 'timestamp_start']\n",
        "        next_start_time = df.loc[i + 1, 'timestamp_start']\n",
        "        seconds = int(next_start_time.split(':')[2].split(',')[0])\n",
        "        rounded_down = math.floor(seconds)\n",
        "        df.loc[i, 'timestamp_end'] = next_start_time.split(':')[0] + ':' + next_start_time.split(':')[1] + ':' + str(rounded_down).zfill(2)\n",
        "\n",
        "    # Fill in the last row with an empty value for timestamp_end\n",
        "    df.loc[len(df) - 1, 'timestamp_end'] = ''\n",
        "\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "id": "nAhbTgSVz8zj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_srt_file(df, filename):\n",
        "    with open(filename, 'w') as f:\n",
        "        for i, row in df.iterrows():\n",
        "            f.write(str(row['block_id']) + '\\n')\n",
        "            f.write(str(row['timestamp_start']).replace(',', '.') + ' --> ' + str(row['timestamp_end']).replace(',', '.') + '\\n')\n",
        "            f.write(str(row['text']) + '\\n')  # Convert 'text' to string\n",
        "            f.write('\\n')"
      ],
      "metadata": {
        "id": "PUFvWAtrxX37"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_last_timestamp_end(df):\n",
        "    last_row = df.iloc[-1]  # Get the last row of the DataFrame\n",
        "    timestamp_end = last_row['timestamp_end']  # Extract the 'timestamp_end' value from the last row\n",
        "    return timestamp_end\n"
      ],
      "metadata": {
        "id": "AJun-2SG2jC0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Usage"
      ],
      "metadata": {
        "id": "NXSpvyOI6D8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "source_file = '/content/eli_Yomjerusalem_5777 (2).srt' # enter your source srt here\n",
        "\n",
        "df = parse_srt_to_df(source_file)\n",
        "last_timestamp_end = get_last_timestamp_end(df)\n",
        "df = merge_text_pairs(df)\n",
        "df = round_down_timestamps(df)\n",
        "df.iloc[-1, df.columns.get_loc('timestamp_end')] = last_timestamp_end\n",
        "create_srt_file(df, f'{source_file[0:-4]}_updated.srt')\n"
      ],
      "metadata": {
        "id": "Kk8s7_lDyr1t"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}