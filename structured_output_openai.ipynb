{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "w7pkNVobDx-L"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMTynPWyFWod6vXcl4Im6O9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deedeeharris/AI/blob/main/structured_output_openai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb56b4d3"
      },
      "source": [
        "# Structured Output with OpenAI and Pydantic\n",
        "\n",
        "**By:** Yedidya Harris (July, 2025)\n",
        "\n",
        "This notebook demonstrates how to use the OpenAI Python SDK (v1.93.0+) and Pydantic (v2+) to get structured output from OpenAI models. It provides a reusable function `get_structured_response` that takes a Pydantic model schema and a user message to guide the AI in generating output that conforms to the specified structure.\n",
        "\n",
        "The notebook includes examples of using the `get_structured_response` function for:\n",
        "\n",
        "  - Summarizing a product review into a structured format (product, sentiment, pros, cons).\n",
        "  - Generating a multiple-choice question with defined question, choices, and correct answer fields.\n",
        "  - Analyzing a conversation to determine its level (beginner, intermediate, advanced) and provide a justification.\n",
        "\n",
        "## Why Use Structured Outputs?\n",
        "\n",
        "Structured outputs allow you to:\n",
        "\n",
        "  * **Reliably extract data** in a predictable, type-safe format (e.g., JSON, Pydantic models).\n",
        "  * **Integrate AI results** directly into applications, databases, or pipelines without fragile string parsing.\n",
        "  * **Enforce schemas** so your AI outputs are always what you expectâ€”no more guessing or post-processing headaches\\!\n",
        "\n",
        "**When to use structured outputs:**\n",
        "\n",
        "  * When you need the AI to return data in a specific format (e.g., for forms, APIs, analytics, or downstream automation).\n",
        "  * For tasks like data extraction, content generation with specific fields, classification, summarization, or any scenario where structure matters.\n",
        "\n",
        "-----\n",
        "\n",
        "## Requirements\n",
        "\n",
        "  * Python **3.8+** (recommended: 3.9+)\n",
        "  * OpenAI Python SDK **v1.93.0+**\n",
        "  * Pydantic **v2.0+**\n",
        "\n",
        "Install with:\n",
        "\n",
        "```bash\n",
        "pip install --upgrade openai pydantic\n",
        "```\n",
        "\n",
        "-----\n",
        "\n",
        "**Important:** Never share your API key in public code or notebooks. Use environment variables or notebook secrets for security.\n",
        "\n",
        "-----\n",
        "\n",
        "## How to Use\n",
        "\n",
        "1.  **Install dependencies:** Run the first code cell to install the necessary libraries (`openai` and `pydantic`).\n",
        "2.  **Set your OpenAI API key:** Replace the placeholder API key in the example usage sections with your actual OpenAI API key. **Note:** For security, it is recommended to use Colab Secrets to store your API key / Or other secure alternatives.\n",
        "3.  **Define your Pydantic model:** Create a Pydantic `BaseModel` subclass that defines the structure of the structured output you expect from the OpenAI model.\n",
        "4.  **Prepare parameters:** Set the `model_name`, `temperature`, `system_prompt` (optional), `chat_history` (optional), `user_message`, and `api_key`.\n",
        "5.  **Call `get_structured_response`:** Use the `get_structured_response` function, passing in the prepared parameters and your Pydantic model class.\n",
        "6.  **Process the structured output:** The function will return an instance of your Pydantic model, containing the structured data from the AI's response.\n",
        "\n",
        "This notebook provides a flexible and type-safe way to interact with OpenAI models for tasks requiring structured output, such as data extraction, content generation with specific formats, and more.\n",
        "\n",
        "-----\n",
        "\n",
        "## Minimal Example\n",
        "\n",
        "```\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class MinimalModel(BaseModel):\n",
        "    message: str\n",
        "\n",
        "result = get_structured_response(\n",
        "    model_name=\"gpt-4.1-nano\",\n",
        "    api_key=\"YOUR_API_KEY\",\n",
        "    user_message=\"Say something nice!\",\n",
        "    pydantic_model=MinimalModel\n",
        ")\n",
        "\n",
        "print(result)\n",
        "```\n",
        "\n",
        "-----\n",
        "\n",
        "## Supported Models\n",
        "\n",
        "  * `gpt-4.1`, `gpt-4.1-mini`, `gpt-4.1-nano` (April 2025+)\n",
        "\n",
        "-----\n",
        "\n",
        "## Parameter Reference\n",
        "\n",
        "| Parameter        | Required? | Default      | Description                          |\n",
        "|:-----------------|:---------:|-------------|--------------------------------------|\n",
        "| `model_name`     | Yes       | \"gpt-4.1\"   | Model to use                         |\n",
        "| `temperature`    | No        | 0.0         | Sampling temperature                 |\n",
        "| `system_prompt`  | No        | None        | System prompt for context            |\n",
        "| `chat_history`   | No        | None        | Previous messages                    |\n",
        "| `pydantic_model` | No        | DefaultModel| Output schema                        |\n",
        "| `user_message`   | No        | None        | User's input message                 |\n",
        "| `api_key`        | Yes       | None        | Your OpenAI API key                  |\n",
        "\n",
        "**Note:** At least one of `user_message`, `system_prompt`, or `chat_history` must be provided. The API will return an error if no input is given."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## My Pydantic and OpenAI Version Numbers"
      ],
      "metadata": {
        "id": "w7pkNVobDx-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pydantic.version\n",
        "print(pydantic.version.version_info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlwIKLdSDh42",
        "outputId": "917ef067-fc50-47f9-b9c0-c1c85dca0562"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             pydantic version: 2.11.7\n",
            "        pydantic-core version: 2.33.2\n",
            "          pydantic-core build: profile=release pgo=false\n",
            "               python version: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "                     platform: Linux-6.1.123+-x86_64-with-glibc2.35\n",
            "             related packages: typing_extensions-4.14.0 fastapi-0.115.14 typing_extensions-4.12.2\n",
            "                       commit: unknown\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib.metadata\n",
        "print(importlib.metadata.version('openai'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFs2y-yMDmuo",
        "outputId": "88aeb37e-4ee6-4fb3-9ecd-c15244b6e806"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.93.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Function and Full Example"
      ],
      "metadata": {
        "id": "2XJqPBDWAIUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies if needed\n",
        "!pip install --upgrade openai pydantic\n",
        "\n",
        "from pydantic import BaseModel\n",
        "from openai import OpenAI\n",
        "from typing import List, Optional, Type\n",
        "\n",
        "# 1. Define a default Pydantic model\n",
        "class DefaultModel(BaseModel):\n",
        "    message: str\n",
        "\n",
        "def get_structured_response(\n",
        "    model_name: str = \"gpt-4.1\",\n",
        "    temperature: float = 0.0,\n",
        "    system_prompt: Optional[str] = None,\n",
        "    chat_history: Optional[List[dict]] = None,\n",
        "    pydantic_model: Type[BaseModel] = DefaultModel,  # Default model here\n",
        "    user_message: Optional[str] = None,\n",
        "    api_key: Optional[str] = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Get structured output from OpenAI using the latest SDK and Pydantic schema.\n",
        "\n",
        "    This function interacts with the OpenAI API to generate a response\n",
        "    that conforms to a specified Pydantic model schema.\n",
        "\n",
        "    Args:\n",
        "        model_name: The name of the OpenAI model to use (e.g., \"gpt-4.1\").\n",
        "        temperature: The sampling temperature to use. Higher values mean\n",
        "                     the model will take more risks.\n",
        "        system_prompt: An optional initial system message to guide the model.\n",
        "        chat_history: An optional list of previous messages in the conversation.\n",
        "        pydantic_model: The Pydantic model class to use for structuring the output.\n",
        "        user_message: The user's current message.\n",
        "        api_key: An optional OpenAI API key. Defaults to using the environment variable.\n",
        "\n",
        "    Returns:\n",
        "        An instance of the provided Pydantic model containing the parsed response.\n",
        "    \"\"\"\n",
        "    # Initialize OpenAI client\n",
        "    client = OpenAI(api_key=api_key) if api_key else OpenAI()\n",
        "\n",
        "    # Build message sequence\n",
        "    messages = []\n",
        "    if system_prompt:\n",
        "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
        "    if chat_history:\n",
        "        messages.extend(chat_history)\n",
        "    if user_message:\n",
        "      messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "    # Call the API with structured output parsing\n",
        "    response = client.responses.parse(\n",
        "        model=model_name,\n",
        "        input=messages,\n",
        "        text_format=pydantic_model,\n",
        "        temperature=temperature,\n",
        "    )\n",
        "    return response.output_parsed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2o5vGrkk8cC4",
        "outputId": "11b1bcb5-e2ca-4e24-bc56-09740ea1a4eb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.93.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.7)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Example usage ---\n",
        "\n",
        "# 1. Define a Pydantic model for the expected output structure\n",
        "class ProductReview(BaseModel):\n",
        "    product: str\n",
        "    sentiment: str\n",
        "    pros: list[str]\n",
        "    cons: list[str]\n",
        "\n",
        "# 2. Prepare parameters for the API call\n",
        "model_name = \"gpt-4.1\"\n",
        "temperature = 0.2\n",
        "system_prompt = \"You are an assistant that summarizes product reviews in structured form.\"\n",
        "chat_history = []  # Or previous messages if you have them\n",
        "user_message = \"I love the new Acme headphones. The sound is amazing, but the battery life is a bit short.\"\n",
        "api_key = \"OPENAI_API_KEY\"\n",
        "\n",
        "# 3. Call the get_structured_response function\n",
        "result = get_structured_response(\n",
        "    model_name=model_name,\n",
        "    temperature=temperature,\n",
        "    system_prompt=system_prompt,\n",
        "    chat_history=chat_history,\n",
        "    pydantic_model=ProductReview,\n",
        "    user_message=user_message,\n",
        "    api_key=api_key\n",
        ")\n",
        "\n",
        "# 4. Print the structured result\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MgS4AYeDFcs",
        "outputId": "1c92cb02-8cce-4c72-adf3-581902fdb205"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "product='Acme headphones' sentiment='positive' pros=['Amazing sound quality'] cons=['Short battery life']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Choice Question - Example"
      ],
      "metadata": {
        "id": "j951ynTt_1Zd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define your Pydantic model for a Multiple Choice Question\n",
        "from pydantic import BaseModel\n",
        "from typing import List\n",
        "\n",
        "class MultipleChoiceQuestion(BaseModel):\n",
        "    question: str\n",
        "    choices: List[str]\n",
        "    correct_answer: str  # The text of the correct choice\n",
        "\n",
        "# 2. Prepare your parameters\n",
        "model_name = \"gpt-4.1\"\n",
        "temperature = 0.2\n",
        "system_prompt = \"You are an assistant that generates multiple choice questions in structured form.\"\n",
        "chat_history = []  # Or previous messages if you have them\n",
        "user_message = (\n",
        "    \"Create a multiple choice question about the water cycle for 5th grade students. \"\n",
        "    \"Provide four answer options and indicate the correct answer.\"\n",
        ")\n",
        "api_key = \"OPENAI_API_KEY\"\n",
        "\n",
        "# 3. Call the function\n",
        "result = get_structured_response(\n",
        "    model_name=model_name,\n",
        "    temperature=temperature,\n",
        "    system_prompt=system_prompt,\n",
        "    chat_history=chat_history,\n",
        "    pydantic_model=MultipleChoiceQuestion,\n",
        "    user_message=user_message,\n",
        "    api_key=api_key\n",
        ")\n",
        "\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFRyViOd2ljd",
        "outputId": "4984cbe7-e812-4da3-d40f-4524b9a16d55"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "question='Which process in the water cycle involves water changing from a liquid to a gas?' choices=['Condensation', 'Evaporation', 'Precipitation', 'Collection'] correct_answer='Evaporation'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Conversation Level Analysis - Example"
      ],
      "metadata": {
        "id": "q9jJFDOVADb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "from openai import OpenAI\n",
        "from typing import List, Optional\n",
        "\n",
        "\n",
        "# 2. Define your Pydantic model for conversation analysis\n",
        "class ConversationAnalysis(BaseModel):\n",
        "    level: str  # e.g., \"beginner\", \"intermediate\", \"advanced\"\n",
        "    justification: str  # Explanation of why this level was chosen\n",
        "\n",
        "# 3. Prepare model parameters and a chat history with multiple messages\n",
        "model_name = \"gpt-4.1-nano\"\n",
        "temperature = 0.2\n",
        "system_prompt = (\n",
        "    \"You are an assistant that analyzes the level of a conversation \"\n",
        "    \"and explains your reasoning. Levels are: beginner, intermediate, advanced.\"\n",
        ")\n",
        "\n",
        "chat_history = [\n",
        "    {\"role\": \"user\", \"content\": \"Hi, can you tell me what an API is?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Sure! An API is an Application Programming Interface. It lets programs talk to each other.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Can you give an example?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"For example, when you use a weather app, it gets data from a weather service using an API.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Is it hard to use an API?\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Not really! Many APIs have good documentation and examples to help you get started.\"},\n",
        "]\n",
        "\n",
        "user_message = \"Analyze the above conversation and determine its level. Explain your reasoning.\"\n",
        "api_key = \"OPENAI_API_KEY\"\n",
        "\n",
        "# 4. Call the function and print the result\n",
        "result = get_structured_response(\n",
        "    model_name=model_name,\n",
        "    temperature=temperature,\n",
        "    system_prompt=system_prompt,\n",
        "    chat_history=chat_history,\n",
        "    pydantic_model=ConversationAnalysis,\n",
        "    user_message=user_message,\n",
        "    api_key=api_key\n",
        ")\n",
        "\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKu_OL7tAA0Z",
        "outputId": "9d66e04a-81a1-4312-a351-a683e588560f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "level='beginner' justification='The conversation involves basic questions and explanations about APIs, suitable for someone new to the topic. The questions are simple and focus on fundamental understanding, indicating a beginner level.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Minimal Parameters - Example"
      ],
      "metadata": {
        "id": "koLN6P-RDMOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "from openai import OpenAI\n",
        "from typing import List, Optional\n",
        "\n",
        "# Define your Pydantic model just before the function call\n",
        "class ComplimentModel(BaseModel):\n",
        "    message: str\n",
        "    language: str\n",
        "    compliments: List[str]\n",
        "\n",
        "api_key = \"OPENAI_API_KEY\"\n",
        "\n",
        "for i in range(3):\n",
        "  result = get_structured_response(\n",
        "      model_name=\"gpt-4.1-nano\",\n",
        "      temperature = 1,\n",
        "      api_key=api_key,\n",
        "      user_message=\"Say something nice in any language you choose!\",\n",
        "      pydantic_model=ComplimentModel\n",
        "  )\n",
        "  print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr96BHDUBMmC",
        "outputId": "20cf0d91-896c-4c29-fb37-8450fde1fd93"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "message='Your kindness radiates and makes the world a brighter place.' language='English' compliments=[\"You're truly appreciated.\", 'Your smile is contagious.', 'You have a wonderful personality.']\n",
            "message='La belleza de una sonrisa puede iluminar incluso el dÃ­a mÃ¡s gris.' language='Spanish' compliments=['You have a wonderful smile!', 'Your kindness is contagious.', 'You are truly appreciated.']\n",
            "message='Your kindness brightens the world today!' language='English' compliments=['You have a wonderful smile!', 'Your positivity is infectious!', \"You're truly appreciated!\"]\n"
          ]
        }
      ]
    }
  ]
}